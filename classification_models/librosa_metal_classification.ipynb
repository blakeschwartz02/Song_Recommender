{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Classification models for the metal subgenre data post feature extraction. \n",
    "This file is to be run on the features extracted from the metal_feature_extractor.py file, not VGGish.\n",
    "To use the file, just change the directory to the directory of your project.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "import os\n",
    "os.chdir('C:\\\\Users\\\\blake\\\\OneDrive - The University of Texas at Austin\\\\Project')\n",
    "\n",
    "metal_df = pd.read_csv('Data\\\\metal_features.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2008, 64)\n",
      "(2008, 64)\n"
     ]
    }
   ],
   "source": [
    "print(metal_df.shape)\n",
    "metal_df = metal_df.dropna()\n",
    "print(metal_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1960, 64)\n"
     ]
    }
   ],
   "source": [
    "metal_df = metal_df.drop_duplicates(subset='title', keep=\"first\")\n",
    "print(metal_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           tempo  zcr_mean   zcr_var  rmse_mean  rmse_var  centroid_mean   \n",
      "0     151.999081  0.074351  0.001561   0.114258  0.002752    2181.215203  \\\n",
      "1      66.256010  0.111619  0.004041   0.018642  0.000021    2509.989081   \n",
      "2     161.499023  0.107580  0.002811   0.084716  0.000365    2343.956293   \n",
      "3     161.499023  0.110319  0.002615   0.076693  0.000777    2424.316543   \n",
      "4     151.999081  0.089109  0.001700   0.152179  0.003460    2391.270454   \n",
      "...          ...       ...       ...        ...       ...            ...   \n",
      "2003  172.265625  0.179256  0.003895   0.054047  0.000416    3318.041756   \n",
      "2004   95.703125  0.156924  0.000821   0.159225  0.001927    2455.779320   \n",
      "2005   89.102909  0.158438  0.000756   0.158723  0.000822    2974.813046   \n",
      "2006  123.046875  0.144889  0.001550   0.060306  0.000275    2763.773133   \n",
      "2007   99.384014  0.130489  0.000954   0.139728  0.001106    2393.238356   \n",
      "\n",
      "       centroid_var  bandwidth_mean  bandwidth_var  contrast_mean  ...   \n",
      "0     482610.507049     2558.850666  174764.598383      21.296943  ...  \\\n",
      "1     844148.519051     2572.406109  246261.986102      22.539447  ...   \n",
      "2     716615.371758     2474.222708  340194.578739      22.117780  ...   \n",
      "3     612365.527333     2492.341742  241954.945353      21.343718  ...   \n",
      "4     448760.061988     2641.490260  151274.051444      22.995294  ...   \n",
      "...             ...             ...            ...            ...  ...   \n",
      "2003  280698.311680     2752.973537   68262.169549      19.941042  ...   \n",
      "2004   69023.231425     2090.054170   93805.436561      20.621860  ...   \n",
      "2005   73121.042523     2626.600472   37562.709773      20.578968  ...   \n",
      "2006  211629.171008     2488.216681  106243.679110      20.900144  ...   \n",
      "2007  255398.044483     2223.942628  201966.304699      21.392127  ...   \n",
      "\n",
      "      mfcc16_mean  mfcc16_var  mfcc17_mean  mfcc17_var  mfcc18_mean   \n",
      "0        0.592374   32.585410    -2.084050   23.633520    -1.124526  \\\n",
      "1        6.129311   34.933400    -7.698192   41.718480    -0.720495   \n",
      "2        5.128003   26.396950    -6.747054   30.311937     0.694298   \n",
      "3        2.093907   28.635975    -5.482922   27.961150     1.806943   \n",
      "4        4.126497   40.205240    -3.384828   35.070404    -0.047709   \n",
      "...           ...         ...          ...         ...          ...   \n",
      "2003     0.415713   18.897371    -3.820183   25.815790    -0.236608   \n",
      "2004    -1.320289   23.298548    -8.588392   33.177296    -2.938309   \n",
      "2005    -0.804291   25.815720    -5.401749   16.727884    -2.288102   \n",
      "2006    -3.206482   18.866701    -7.377448   20.212032    -6.647660   \n",
      "2007     5.092002   23.933926    -2.520834   27.309591     0.576603   \n",
      "\n",
      "      mfcc18_var  mfcc19_mean  mfcc19_var  mfcc20_mean  mfcc20_var  \n",
      "0      28.282341    -0.585091   28.417725    -1.251430   22.480503  \n",
      "1      33.528008    -2.418910   30.387417    -1.870767   28.643364  \n",
      "2      35.899055    -1.424906   32.738450    -0.471814   32.966187  \n",
      "3      28.260510    -1.277048   28.995024    -0.366549   35.731552  \n",
      "4      57.063650    -2.328597   34.096700    -2.180690   46.112010  \n",
      "...          ...          ...         ...          ...         ...  \n",
      "2003   19.299862    -1.737713   20.367432     1.836022   18.513490  \n",
      "2004   31.151134    -0.684279   33.096900    -2.521253   18.757652  \n",
      "2005   19.380968    -0.139133   21.484268    -1.689018   21.136440  \n",
      "2006   16.984290    -2.452555   21.935274     1.481844   20.904577  \n",
      "2007   25.018385    -0.539950   17.986185     2.919788   30.386162  \n",
      "\n",
      "[1960 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "X = metal_df.drop(columns=['title', 'Unnamed: 0', 'subgenre'])\n",
    "y = metal_df['subgenre']\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "2003    10\n",
      "2004    10\n",
      "2005    10\n",
      "2006    10\n",
      "2007    10\n",
      "Name: subgenre, Length: 1960, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def label_to_int(label):\n",
    "    if label == 'alternative':\n",
    "        return 0\n",
    "    elif label == 'death':\n",
    "        return 1\n",
    "    elif label == 'folk':\n",
    "        return 2\n",
    "    elif label == 'glam':\n",
    "        return 3\n",
    "    elif label == 'industrial':\n",
    "        return 4\n",
    "    elif label == 'metalcore':\n",
    "        return 5\n",
    "    elif label == 'nu':\n",
    "        return 6\n",
    "    elif label == 'NWOBHM':\n",
    "        return 7\n",
    "    elif label == 'progressive':\n",
    "        return 8\n",
    "    elif label == 'symphonic':\n",
    "        return 9\n",
    "    elif label == 'thrash':\n",
    "        return 10\n",
    "    \n",
    "def calculate_accuracy(model, X, Y):\n",
    "    accuracy = metrics.accuracy_score(Y, model.predict(X))\n",
    "    return accuracy\n",
    "    \n",
    "y = y.apply(lambda x: label_to_int(x))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train dimension=  (1568, 61)\n",
      "X_test dimension=  (392, 61)\n",
      "y_train dimension=  (1568,)\n",
      "y_train dimension=  (392,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size= 0.2, random_state = 1)\n",
    "\n",
    "print('X_train dimension= ', X_train.shape)\n",
    "print('X_test dimension= ', X_test.shape)\n",
    "print('y_train dimension= ', y_train.shape)\n",
    "print('y_train dimension= ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27  3  1  0  0  0  9  0  0  0  0]\n",
      " [10 26  1  0  0  0  7  0  0  0  0]\n",
      " [11  1 25  0  0  0 14  0  0  0  0]\n",
      " [ 6  1 12  0  0  0  2  0  0  0  0]\n",
      " [15  7  1  0  0  0 14  0  0  0  0]\n",
      " [30  3  0  0  0  0 13  0  0  0  0]\n",
      " [ 5  7  1  0  0  0 18  0  0  0  0]\n",
      " [ 6  4  0  0  0  0 10  0  0  0  0]\n",
      " [26  7  1  0  0  0 11  0  0  0  0]\n",
      " [26  1  3  0  0  0  1  0  0  0  0]\n",
      " [23  2  3  0  0  0  8  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "dtree_model = DecisionTreeClassifier(max_depth=2).fit(X_train, y_train)\n",
    "dtree_predictions = dtree_model.predict(X_test)\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, dtree_predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, random_state = 0)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17729083665338646\n",
      "[[ 8 10  4  2  1  5  7  1 14  1  0]\n",
      " [12 17  6  1  4  5  0  1  4  0  5]\n",
      " [ 7  1 21  2  6  8  5  0  2  1  8]\n",
      " [ 1  2 10  5  3  3  2  0  1  1  4]\n",
      " [ 3  3 17  1 10  8  2  1  3  0  1]\n",
      " [ 9  5 12  0  6  5  2  2  9  0  2]\n",
      " [ 8  7  4  1  4  3  7  1  7  0  1]\n",
      " [ 1  3  1  1  1  1  6  0  3  0  1]\n",
      " [15 11  5  0  1  7  7  1  9  1  3]\n",
      " [ 3  8  6  2  2  1  2  1  3  2  4]\n",
      " [ 5  9 11  2  2  5  4  1  1  0  5]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 10).fit(X_train, y_train)\n",
    "accuracy = knn.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "\n",
    "knn_predictions = knn.predict(X_test) \n",
    "cm = metrics.confusion_matrix(y_test, knn_predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17928286852589642\n",
      "[[ 5  1  1  4  1  2  1  2 23 13  0]\n",
      " [ 2  9  0  3  0  0  1  1  6 33  0]\n",
      " [ 0  0  0 32  2  2  1  1  6 17  0]\n",
      " [ 0  1  1 21  2  1  0  0  1  5  0]\n",
      " [ 1  0  3  9  0  1  0  1 12 20  2]\n",
      " [ 0  0  0  3  0  3  0  2 16 28  0]\n",
      " [ 0  2  1  6  1  0  1  5 20  7  0]\n",
      " [ 0  0  0  2  1  2  0  4  7  1  1]\n",
      " [ 7  0  0  8  2  0  2  4 26 11  0]\n",
      " [ 2  0  0  5  1  1  1  0  4 20  0]\n",
      " [ 0  0  0  7  0  4  0  2  6 25  1]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, random_state = 0)\n",
    "  \n",
    "# training a Naive Bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB().fit(X_train, y_train)\n",
    "gnb_predictions = gnb.predict(X_test)\n",
    "  \n",
    "# accuracy on X_test\n",
    "accuracy = gnb.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "  \n",
    "# creating a confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, gnb_predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF THE MODEL:  0.47619047619047616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size = 0.30)\n",
    "clf = RandomForestClassifier(n_estimators = 1000)  \n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "92/92 [==============================] - 1s 4ms/step - loss: 5615.9268 - accuracy: 0.1027 - val_loss: 2494.2158 - val_accuracy: 0.0633\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 1893.1406 - accuracy: 0.0891 - val_loss: 1289.6982 - val_accuracy: 0.0796\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2068.2161 - accuracy: 0.1170 - val_loss: 1833.8900 - val_accuracy: 0.1408\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 1824.5847 - accuracy: 0.0918 - val_loss: 984.2502 - val_accuracy: 0.0776\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 945.1339 - accuracy: 0.0884 - val_loss: 837.1351 - val_accuracy: 0.1020\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 308.2831 - accuracy: 0.0803 - val_loss: 3.0297 - val_accuracy: 0.1184\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.4171 - accuracy: 0.1211 - val_loss: 2.9038 - val_accuracy: 0.1184\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3933 - accuracy: 0.1218 - val_loss: 2.9011 - val_accuracy: 0.1184\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3905 - accuracy: 0.1218 - val_loss: 2.8988 - val_accuracy: 0.1184\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3878 - accuracy: 0.1218 - val_loss: 2.8968 - val_accuracy: 0.1184\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3852 - accuracy: 0.1218 - val_loss: 2.8948 - val_accuracy: 0.1184\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3829 - accuracy: 0.1218 - val_loss: 2.8931 - val_accuracy: 0.1184\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3807 - accuracy: 0.1218 - val_loss: 2.8915 - val_accuracy: 0.1184\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3786 - accuracy: 0.1218 - val_loss: 2.8899 - val_accuracy: 0.1184\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3768 - accuracy: 0.1218 - val_loss: 2.8886 - val_accuracy: 0.1184\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3752 - accuracy: 0.1218 - val_loss: 2.8875 - val_accuracy: 0.1184\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 2.3736 - accuracy: 0.1218 - val_loss: 2.8865 - val_accuracy: 0.1184\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3723 - accuracy: 0.1218 - val_loss: 2.8857 - val_accuracy: 0.1184\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 2.3711 - accuracy: 0.1218 - val_loss: 2.8849 - val_accuracy: 0.1184\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3700 - accuracy: 0.1218 - val_loss: 2.8843 - val_accuracy: 0.1184\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3691 - accuracy: 0.1218 - val_loss: 2.8838 - val_accuracy: 0.1184\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3682 - accuracy: 0.1218 - val_loss: 2.8834 - val_accuracy: 0.1184\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3675 - accuracy: 0.1218 - val_loss: 2.8829 - val_accuracy: 0.1184\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3668 - accuracy: 0.1218 - val_loss: 2.8826 - val_accuracy: 0.1184\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3663 - accuracy: 0.1218 - val_loss: 2.8824 - val_accuracy: 0.1184\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3658 - accuracy: 0.1218 - val_loss: 2.8823 - val_accuracy: 0.1184\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3654 - accuracy: 0.1218 - val_loss: 2.8820 - val_accuracy: 0.1184\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3650 - accuracy: 0.1218 - val_loss: 2.8818 - val_accuracy: 0.1184\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3647 - accuracy: 0.1218 - val_loss: 2.8819 - val_accuracy: 0.1184\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3644 - accuracy: 0.1218 - val_loss: 2.8819 - val_accuracy: 0.1184\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3642 - accuracy: 0.1218 - val_loss: 2.8818 - val_accuracy: 0.1184\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3640 - accuracy: 0.1218 - val_loss: 2.8817 - val_accuracy: 0.1184\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3639 - accuracy: 0.1218 - val_loss: 2.8819 - val_accuracy: 0.1184\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3637 - accuracy: 0.1218 - val_loss: 2.8819 - val_accuracy: 0.1184\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3635 - accuracy: 0.1218 - val_loss: 2.8819 - val_accuracy: 0.1184\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3635 - accuracy: 0.1218 - val_loss: 2.8820 - val_accuracy: 0.1184\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3634 - accuracy: 0.1218 - val_loss: 2.8818 - val_accuracy: 0.1184\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3633 - accuracy: 0.1218 - val_loss: 2.8820 - val_accuracy: 0.1184\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3632 - accuracy: 0.1218 - val_loss: 2.8820 - val_accuracy: 0.1184\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3631 - accuracy: 0.1218 - val_loss: 2.8822 - val_accuracy: 0.1184\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3632 - accuracy: 0.1218 - val_loss: 2.8821 - val_accuracy: 0.1184\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3631 - accuracy: 0.1218 - val_loss: 2.8821 - val_accuracy: 0.1184\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3631 - accuracy: 0.1218 - val_loss: 2.8823 - val_accuracy: 0.1184\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3630 - accuracy: 0.1218 - val_loss: 2.8823 - val_accuracy: 0.1184\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3630 - accuracy: 0.1218 - val_loss: 2.8822 - val_accuracy: 0.1184\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3630 - accuracy: 0.1218 - val_loss: 2.8822 - val_accuracy: 0.1184\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3630 - accuracy: 0.1218 - val_loss: 2.8822 - val_accuracy: 0.1184\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 2.3630 - accuracy: 0.1218 - val_loss: 2.8824 - val_accuracy: 0.1184\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3630 - accuracy: 0.1218 - val_loss: 2.8823 - val_accuracy: 0.1184\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8824 - val_accuracy: 0.1184\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8824 - val_accuracy: 0.1184\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3631 - accuracy: 0.1218 - val_loss: 2.8825 - val_accuracy: 0.1184\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8824 - val_accuracy: 0.1184\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3630 - accuracy: 0.1218 - val_loss: 2.8826 - val_accuracy: 0.1184\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8825 - val_accuracy: 0.1184\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8825 - val_accuracy: 0.1184\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3630 - accuracy: 0.1218 - val_loss: 2.8826 - val_accuracy: 0.1184\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8826 - val_accuracy: 0.1184\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8826 - val_accuracy: 0.1184\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8827 - val_accuracy: 0.1184\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8828 - val_accuracy: 0.1184\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8826 - val_accuracy: 0.1184\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8826 - val_accuracy: 0.1184\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3630 - accuracy: 0.1218 - val_loss: 2.8826 - val_accuracy: 0.1184\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8827 - val_accuracy: 0.1184\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8828 - val_accuracy: 0.1184\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8827 - val_accuracy: 0.1184\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8827 - val_accuracy: 0.1184\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3630 - accuracy: 0.1218 - val_loss: 2.8827 - val_accuracy: 0.1184\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8828 - val_accuracy: 0.1184\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8828 - val_accuracy: 0.1184\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8826 - val_accuracy: 0.1184\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3630 - accuracy: 0.1218 - val_loss: 2.8827 - val_accuracy: 0.1184\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3630 - accuracy: 0.1218 - val_loss: 2.8826 - val_accuracy: 0.1184\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3630 - accuracy: 0.1218 - val_loss: 2.8828 - val_accuracy: 0.1184\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8827 - val_accuracy: 0.1184\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3630 - accuracy: 0.1218 - val_loss: 2.8828 - val_accuracy: 0.1184\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8827 - val_accuracy: 0.1184\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8828 - val_accuracy: 0.1184\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8828 - val_accuracy: 0.1184\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8827 - val_accuracy: 0.1184\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8828 - val_accuracy: 0.1184\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3630 - accuracy: 0.1218 - val_loss: 2.8828 - val_accuracy: 0.1184\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3630 - accuracy: 0.1218 - val_loss: 2.8829 - val_accuracy: 0.1184\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8827 - val_accuracy: 0.1184\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8828 - val_accuracy: 0.1184\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8827 - val_accuracy: 0.1184\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8827 - val_accuracy: 0.1184\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8827 - val_accuracy: 0.1184\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3630 - accuracy: 0.1218 - val_loss: 2.8826 - val_accuracy: 0.1184\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8828 - val_accuracy: 0.1184\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8828 - val_accuracy: 0.1184\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8828 - val_accuracy: 0.1184\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3630 - accuracy: 0.1218 - val_loss: 2.8828 - val_accuracy: 0.1184\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8828 - val_accuracy: 0.1184\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8828 - val_accuracy: 0.1184\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8828 - val_accuracy: 0.1184\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3630 - accuracy: 0.1218 - val_loss: 2.8826 - val_accuracy: 0.1184\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8828 - val_accuracy: 0.1184\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 2.3629 - accuracy: 0.1218 - val_loss: 2.8827 - val_accuracy: 0.1184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19cb1c0abf0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, random_state = 0)\n",
    "\n",
    "model=tf.keras.models.Sequential([\n",
    "        layers.Conv1D(64, 3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        layers.MaxPooling1D(2),\n",
    "        layers.Conv1D(32, 3, activation='relu'),\n",
    "        layers.MaxPooling1D(2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(11, activation='softmax')   \n",
    "    ])\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, random_state = 0)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 100, 100), max_iter=500, alpha=0.001,solver='sgd', verbose=0,  random_state=21,tol=0.000000001, activation='relu', learning_rate='adaptive')\n",
    "mlp.fit(X_train, y_train)\n",
    "print(calculate_accuracy(mlp, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34285714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\blake\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, random_state = 0)\n",
    "logreg = LogisticRegression(max_iter=100000)\n",
    "logreg.fit(X_train, y_train)\n",
    "print(calculate_accuracy(logreg, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\blake\\OneDrive - The University of Texas at Austin\\Project\\Test Code\\feature_extractor.py:11: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio_file = librosa.load(audio_path, offset=60.0, duration=30.0)\n",
      "c:\\Users\\blake\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    }
   ],
   "source": [
    "import feature_extractor\n",
    "input_path = 'Data\\\\girls_girls_girls.wav'\n",
    "input_features = feature_extractor.extract_features_from_wav_file(input_path)\n",
    "input_features = input_features.drop(['title'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4']\n"
     ]
    }
   ],
   "source": [
    "input_pred = clf.predict(input_features)\n",
    "print(input_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
