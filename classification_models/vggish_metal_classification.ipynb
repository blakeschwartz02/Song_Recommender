{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Run multiple classification models on the VGGish extracted features. \n",
    "To use, just change the source directory of the metal features file.\n",
    "Use this after running the extract_features_from_metal.py file in the vggish_feature_extraction folder.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   song        genre   \n",
      "0      1. The Hollow - a perfect circle-avgiqNapUx0.wav  alternative  \\\n",
      "1     10 Years - Beautiful (Official Video)-C6iQpkkW...  alternative   \n",
      "2                     10 Years - Fix Me-DCbkeUxkbYc.wav  alternative   \n",
      "3               10 Years - Shoot It Out-3VCvSJo-yC0.wav  alternative   \n",
      "4             10 Years - Waking Up [HD]-kHg_XwPuY2E.wav  alternative   \n",
      "...                                                 ...          ...   \n",
      "2002  Wehrmacht - You Broke My Heart, So I Broke You...       thrash   \n",
      "2003   Whiplash - Power Thrashing Death-IVX4tumzsn0.wav       thrash   \n",
      "2004        Whiplash-Burning Of Atlanta-ByUD7JemXzU.wav       thrash   \n",
      "2005      XENTRIX - For Whose Advantage-_0M9Tl1fx4Y.wav       thrash   \n",
      "2006  ùóñùóîùó•ùóñùóîùó¶ùó¶ ''1985 ‚Ä† Thrasher's Abattoir'' [Melo D...       thrash   \n",
      "\n",
      "      Feature 0  Feature 1  Feature 2  Feature 3  Feature 4  Feature 5   \n",
      "0     -0.228171  -0.023990  -0.124108   0.326429  -0.028174  -0.066432  \\\n",
      "1     -0.269944  -0.054643  -0.137082   0.295747  -0.050220  -0.071286   \n",
      "2     -0.136545  -0.040878   0.054774  -0.112809   0.478004  -0.451815   \n",
      "3     -0.190804  -0.158526   0.090571  -0.021802   0.052155  -0.088990   \n",
      "4     -0.385523  -0.313010   1.484148  -0.476138  -0.054587  -0.689774   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "2002  -0.516022  -0.176723   0.385820  -0.044602  -0.123703  -0.434634   \n",
      "2003  -0.365233  -0.116644   0.405251   0.077717  -0.174589  -0.808176   \n",
      "2004  -0.681762  -0.319739   0.189486  -0.128989   0.048446  -0.467320   \n",
      "2005  -0.226703   0.097376   0.189616  -0.267308   0.362961  -0.173257   \n",
      "2006  -0.573772  -0.248708   0.199918  -0.025619   0.059997  -0.414679   \n",
      "\n",
      "      Feature 6  Feature 7  ...  Feature 16372  Feature 16373  Feature 16374   \n",
      "0     -0.048512  -0.111071  ...      -0.114261       0.965333       0.082692  \\\n",
      "1     -0.042822  -0.105079  ...      -0.037979       0.481075       0.303045   \n",
      "2     -0.133681   0.213353  ...      -0.142279       0.580250       0.072944   \n",
      "3     -0.045691  -0.063592  ...      -0.423763       0.239508       0.418080   \n",
      "4      0.045765  -0.004734  ...      -0.294104       0.596722       0.771093   \n",
      "...         ...        ...  ...            ...            ...            ...   \n",
      "2002   0.191126  -0.019841  ...            NaN            NaN            NaN   \n",
      "2003  -0.402332  -0.135967  ...      -0.059365       0.205815      -0.332273   \n",
      "2004  -0.025569  -0.012010  ...      -0.160784       0.151416      -0.357446   \n",
      "2005  -0.363470  -0.359203  ...       0.083561       0.451313       0.071091   \n",
      "2006   0.007470   0.055624  ...      -0.098343       0.490159      -0.231182   \n",
      "\n",
      "      Feature 16375  Feature 16376  Feature 16377  Feature 16378   \n",
      "0         -0.076503      -0.427477      -0.193519      -0.393155  \\\n",
      "1         -0.161835      -0.330621       0.095256      -0.319832   \n",
      "2         -0.098331      -0.381932       0.052414      -0.374630   \n",
      "3         -0.242626      -0.578977      -0.232521      -1.027161   \n",
      "4         -0.304890      -0.491254      -0.307466      -0.796878   \n",
      "...             ...            ...            ...            ...   \n",
      "2002            NaN            NaN            NaN            NaN   \n",
      "2003      -0.284472      -0.304016      -0.102036      -0.418799   \n",
      "2004      -0.321055      -0.413646      -0.271039      -0.392815   \n",
      "2005      -0.098173      -0.364713      -0.206001      -0.490984   \n",
      "2006      -0.243962      -0.455339      -0.324507      -0.550800   \n",
      "\n",
      "      Feature 16379  Feature 16380  Feature 16381  \n",
      "0         -0.108662      -0.319035      -0.822354  \n",
      "1          0.133918       0.017596      -0.666791  \n",
      "2          0.114804      -0.225997      -0.580209  \n",
      "3          0.114584      -0.228811      -1.167400  \n",
      "4          0.471907      -0.079039      -1.000866  \n",
      "...             ...            ...            ...  \n",
      "2002            NaN            NaN            NaN  \n",
      "2003       0.315373      -0.178631      -1.133018  \n",
      "2004       0.554220      -0.555720      -1.115832  \n",
      "2005       0.476080      -0.343412      -0.741015  \n",
      "2006       0.583670      -0.851294      -0.508367  \n",
      "\n",
      "[2007 rows x 16384 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\blake\\\\OneDrive - The University of Texas at Austin')\n",
    "\n",
    "metal_features = pd.read_csv('vggish_metal_features.csv')\n",
    "print(metal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2007, 16384)\n",
      "(1995, 16384)\n"
     ]
    }
   ],
   "source": [
    "print(metal_features.shape)\n",
    "metal_features = metal_features.dropna()\n",
    "print(metal_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1947, 16384)\n"
     ]
    }
   ],
   "source": [
    "metal_features = metal_features.drop_duplicates(subset='song', keep=\"first\")\n",
    "print(metal_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_CNN_model(X_train, Y_train, X_test, Y_test):\n",
    "    \n",
    "    # Define the architecture of the CNN\n",
    "    model=tf.keras.models.Sequential([\n",
    "        layers.Conv1D(64, 3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        layers.MaxPooling1D(2),\n",
    "        layers.Conv1D(32, 3, activation='relu'),\n",
    "        layers.MaxPooling1D(2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(11, activation='softmax')   \n",
    "    ])\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, Y_train, epochs=100, batch_size=16, validation_data=(X_test, Y_test))\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_mlp_model(X_train, Y_train, X_test, Y_test):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(100, 100, 100), max_iter=500, alpha=0.001,solver='sgd', verbose=0,  random_state=21,tol=0.000000001, activation='relu', learning_rate='adaptive')\n",
    "    mlp.fit(X_train, Y_train)\n",
    "    return mlp\n",
    "\n",
    "def train_logistic_model(X_train, Y_train, X_test, Y_test):\n",
    "    logreg = LogisticRegression(max_iter=500)\n",
    "    logreg.fit(X_train, Y_train)\n",
    "    return logreg\n",
    "\n",
    "def train_random_forest_model(X_train, y_train, X_test, y_test):\n",
    "    clf = RandomForestClassifier(n_estimators = 1000)  \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"ACCURACY OF THE MODEL: \", accuracy_score(y_test, y_pred))\n",
    "    return clf\n",
    "    \n",
    "def calculate_accuracy(model, X, Y):\n",
    "    accuracy = accuracy_score(Y, model.predict(X))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = metal_features.drop(columns=['song', 'genre'])\n",
    "y = metal_features['genre']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "2001    10\n",
      "2003    10\n",
      "2004    10\n",
      "2005    10\n",
      "2006    10\n",
      "Name: genre, Length: 1947, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def label_to_int(label):\n",
    "    if label == 'alternative':\n",
    "        return 0\n",
    "    elif label == 'death':\n",
    "        return 1\n",
    "    elif label == 'folk':\n",
    "        return 2\n",
    "    elif label == 'glam':\n",
    "        return 3\n",
    "    elif label == 'industrial':\n",
    "        return 4\n",
    "    elif label == 'metalcore':\n",
    "        return 5\n",
    "    elif label == 'nu':\n",
    "        return 6\n",
    "    elif label == 'NWOBHM':\n",
    "        return 7\n",
    "    elif label == 'progressive':\n",
    "        return 8\n",
    "    elif label == 'symphonic':\n",
    "        return 9\n",
    "    elif label == 'thrash':\n",
    "        return 10\n",
    "    \n",
    "y = y.apply(lambda x: label_to_int(x))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\blake\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# cnn_model = train_CNN_model(X_train, y_train, X_test, y_test)\n",
    "mlp_model = train_mlp_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6652977412731006\n"
     ]
    }
   ],
   "source": [
    "print(calculate_accuracy(mlp_model, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF THE MODEL:  0.5626283367556468\n"
     ]
    }
   ],
   "source": [
    "rf_model = train_random_forest_model(X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
