{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNXCDVtJOxBJ7p3egIxWHBu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pijj_ZXyHgTn","executionInfo":{"status":"ok","timestamp":1680890332835,"user_tz":300,"elapsed":20045,"user":{"displayName":"Luke","userId":"06855399274338601976"}},"outputId":"ac9c35f4-2abe-491b-950f-2c57d14b2474"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"OpFLuPwUw6Et","executionInfo":{"status":"ok","timestamp":1680890335220,"user_tz":300,"elapsed":856,"user":{"displayName":"Luke","userId":"06855399274338601976"}}},"outputs":[],"source":["import sklearn\n","import numpy as np\n","import pandas as pd\n","import scipy\n","import matplotlib.pyplot as plt\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation\n","from sklearn import metrics \n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from keras.optimizers import SGD\n","music_data = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/Data/features_30_sec.csv')\n"]},{"cell_type":"code","source":["\n","y = music_data.label\n","features  = music_data.drop(\"label\", axis=1)\n","features = features.drop(\"filename\", axis=1)\n","X_train, X_test, Y_train, Y_test = train_test_split(\n","features, y, test_size=.25, random_state=42)\n","music_data['label'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YnoTYTS7HDvQ","executionInfo":{"status":"ok","timestamp":1680890783948,"user_tz":300,"elapsed":243,"user":{"displayName":"Luke","userId":"06855399274338601976"}},"outputId":"0860d3b2-b7a9-4866-a92c-da166004e051"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["blues        100\n","classical    100\n","country      100\n","disco        100\n","hiphop       100\n","jazz         100\n","metal        100\n","pop          100\n","reggae       100\n","rock         100\n","Name: label, dtype: int64"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["model = Sequential()\n","model.add(Dense(10, input_shape=(features.shape[1],), activation='relu')) # input shape is (features,)\n","model.add(Dense(5, activation='softmax'))\n","model.summary()\n","\n","# compile the model\n","model.compile(optimizer='adam', \n","              loss='categorical_crossentropy', # this is different instead of binary_crossentropy (for regular classification)\n","              metrics=['accuracy'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wu-AdUMyKMRS","executionInfo":{"status":"ok","timestamp":1680891306438,"user_tz":300,"elapsed":391,"user":{"displayName":"Luke","userId":"06855399274338601976"}},"outputId":"d92160f4-3a48-4ae3-ba75-4cdeea982d19"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_8 (Dense)             (None, 10)                590       \n","                                                                 \n"," dense_9 (Dense)             (None, 5)                 55        \n","                                                                 \n","=================================================================\n","Total params: 645\n","Trainable params: 645\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# from medium article\n","from keras.callbacks import EarlyStopping\n","from sklearn.preprocessing import LabelEncoder\n","from keras.utils import np_utils, to_categorical\n","\n","encoder = LabelEncoder()\n","encoder.fit(Y_train)\n","encoded_Y = encoder.transform(Y_train)\n","# convert integers to dummy variables (i.e. one hot encoded)\n","y_train = to_categorical(encoded_Y, 10)\n","\n","encoder = LabelEncoder()\n","encoder.fit(Y_test)\n","encoded_Y = encoder.transform(Y_test)\n","# convert integers to dummy variables (i.e. one hot encoded)\n","y_test = to_categorical(encoded_Y, 10)\n","\n","# early stopping callback\n","# This callback will stop the training when there is no improvement in  \n","# the validation loss for 10 consecutive epochs.  \n","es = keras.callbacks.EarlyStopping(monitor='val_loss', \n","                                   mode='min',\n","                                   patience=10, \n","                                   restore_best_weights=True) # important - otherwise you just return the last weigths...\n","display(features)\n","print(y_train.shape)\n","# now we just update our model fit call\n","history = model.fit(X_train,\n","                    y_train,\n","                    callbacks=[es],\n","                    epochs=8000000, # you can set this to a big number!\n","                    batch_size=10,\n","                    shuffle=True,\n","                    validation_split=0.2,\n","                    validation_data=(X_test, Y_test),\n","                    verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"itoGpWHB7-EK","executionInfo":{"status":"error","timestamp":1680891309543,"user_tz":300,"elapsed":394,"user":{"displayName":"Luke","userId":"06855399274338601976"}},"outputId":"1b604772-377a-43a5-bbfe-89fd34da29a9"},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":["     length  chroma_stft_mean  chroma_stft_var  rms_mean   rms_var  \\\n","0    661794          0.350088         0.088757  0.130228  0.002827   \n","1    661794          0.340914         0.094980  0.095948  0.002373   \n","2    661794          0.363637         0.085275  0.175570  0.002746   \n","3    661794          0.404785         0.093999  0.141093  0.006346   \n","4    661794          0.308526         0.087841  0.091529  0.002303   \n","..      ...               ...              ...       ...       ...   \n","995  661794          0.352063         0.080487  0.079486  0.000345   \n","996  661794          0.398687         0.075086  0.076458  0.000588   \n","997  661794          0.432142         0.075268  0.081651  0.000322   \n","998  661794          0.362485         0.091506  0.083860  0.001211   \n","999  661794          0.358401         0.085884  0.054454  0.000336   \n","\n","     spectral_centroid_mean  spectral_centroid_var  spectral_bandwidth_mean  \\\n","0               1784.165850          129774.064525              2002.449060   \n","1               1530.176679          375850.073649              2039.036516   \n","2               1552.811865          156467.643368              1747.702312   \n","3               1070.106615          184355.942417              1596.412872   \n","4               1835.004266          343399.939274              1748.172116   \n","..                      ...                    ...                      ...   \n","995             2008.149458          282174.689224              2106.541053   \n","996             2006.843354          182114.709510              2068.942009   \n","997             2077.526598          231657.968040              1927.293153   \n","998             1398.699344          240318.731073              1818.450280   \n","999             1609.795082          422203.216152              1797.213044   \n","\n","     spectral_bandwidth_var  rolloff_mean  ...  mfcc16_mean  mfcc16_var  \\\n","0              85882.761315   3805.839606  ...     0.752740   52.420910   \n","1             213843.755497   3550.522098  ...     0.927998   55.356403   \n","2              76254.192257   3042.260232  ...     2.451690   40.598766   \n","3             166441.494769   2184.745799  ...     0.780874   44.427753   \n","4              88445.209036   3579.757627  ...    -4.520576   86.099236   \n","..                      ...           ...  ...          ...         ...   \n","995            88609.749506   4253.557033  ...     1.789867   45.050526   \n","996            82426.016726   4149.338328  ...     3.739020   33.851742   \n","997            74717.124394   4031.405321  ...     1.838090   33.597008   \n","998           109090.207161   3015.631004  ...    -2.812176   46.324894   \n","999           120115.632927   3246.908930  ...     1.794104   59.167755   \n","\n","     mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  \\\n","0      -1.690215   36.524071    -0.408979   41.597103    -2.303523   \n","1      -0.731125   60.314529     0.295073   48.120598    -0.283518   \n","2      -7.729093   47.639427    -1.816407   52.382141    -3.439720   \n","3      -3.319597   50.206673     0.636965   37.319130    -0.619121   \n","4      -5.454034   75.269707    -0.916874   53.613918    -4.404827   \n","..           ...         ...          ...         ...          ...   \n","995   -13.289984   41.754955     2.484145   36.778877    -6.713265   \n","996   -10.848309   39.395096     1.881229   32.010040    -7.461491   \n","997   -12.845291   36.367264     3.440978   36.001110   -12.588070   \n","998    -4.416050   43.583942     1.556207   34.331261    -5.041897   \n","999    -7.069775   73.760391     0.028346   76.504326    -2.025783   \n","\n","     mfcc19_var  mfcc20_mean  mfcc20_var  \n","0     55.062923     1.221291   46.936035  \n","1     51.106190     0.531217   45.786282  \n","2     46.639660    -2.231258   30.573025  \n","3     37.259739    -3.407448   31.949339  \n","4     62.910812   -11.703234   55.195160  \n","..          ...          ...         ...  \n","995   54.866825    -1.193787   49.950665  \n","996   39.196327    -2.795338   31.773624  \n","997   42.502201    -2.106337   29.865515  \n","998   47.227180    -3.590644   41.299088  \n","999   72.189316     1.155239   49.662510  \n","\n","[1000 rows x 58 columns]"],"text/html":["\n","  <div id=\"df-5918a515-1ca0-4231-a1a3-4d7bc3474107\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>length</th>\n","      <th>chroma_stft_mean</th>\n","      <th>chroma_stft_var</th>\n","      <th>rms_mean</th>\n","      <th>rms_var</th>\n","      <th>spectral_centroid_mean</th>\n","      <th>spectral_centroid_var</th>\n","      <th>spectral_bandwidth_mean</th>\n","      <th>spectral_bandwidth_var</th>\n","      <th>rolloff_mean</th>\n","      <th>...</th>\n","      <th>mfcc16_mean</th>\n","      <th>mfcc16_var</th>\n","      <th>mfcc17_mean</th>\n","      <th>mfcc17_var</th>\n","      <th>mfcc18_mean</th>\n","      <th>mfcc18_var</th>\n","      <th>mfcc19_mean</th>\n","      <th>mfcc19_var</th>\n","      <th>mfcc20_mean</th>\n","      <th>mfcc20_var</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>661794</td>\n","      <td>0.350088</td>\n","      <td>0.088757</td>\n","      <td>0.130228</td>\n","      <td>0.002827</td>\n","      <td>1784.165850</td>\n","      <td>129774.064525</td>\n","      <td>2002.449060</td>\n","      <td>85882.761315</td>\n","      <td>3805.839606</td>\n","      <td>...</td>\n","      <td>0.752740</td>\n","      <td>52.420910</td>\n","      <td>-1.690215</td>\n","      <td>36.524071</td>\n","      <td>-0.408979</td>\n","      <td>41.597103</td>\n","      <td>-2.303523</td>\n","      <td>55.062923</td>\n","      <td>1.221291</td>\n","      <td>46.936035</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>661794</td>\n","      <td>0.340914</td>\n","      <td>0.094980</td>\n","      <td>0.095948</td>\n","      <td>0.002373</td>\n","      <td>1530.176679</td>\n","      <td>375850.073649</td>\n","      <td>2039.036516</td>\n","      <td>213843.755497</td>\n","      <td>3550.522098</td>\n","      <td>...</td>\n","      <td>0.927998</td>\n","      <td>55.356403</td>\n","      <td>-0.731125</td>\n","      <td>60.314529</td>\n","      <td>0.295073</td>\n","      <td>48.120598</td>\n","      <td>-0.283518</td>\n","      <td>51.106190</td>\n","      <td>0.531217</td>\n","      <td>45.786282</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>661794</td>\n","      <td>0.363637</td>\n","      <td>0.085275</td>\n","      <td>0.175570</td>\n","      <td>0.002746</td>\n","      <td>1552.811865</td>\n","      <td>156467.643368</td>\n","      <td>1747.702312</td>\n","      <td>76254.192257</td>\n","      <td>3042.260232</td>\n","      <td>...</td>\n","      <td>2.451690</td>\n","      <td>40.598766</td>\n","      <td>-7.729093</td>\n","      <td>47.639427</td>\n","      <td>-1.816407</td>\n","      <td>52.382141</td>\n","      <td>-3.439720</td>\n","      <td>46.639660</td>\n","      <td>-2.231258</td>\n","      <td>30.573025</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>661794</td>\n","      <td>0.404785</td>\n","      <td>0.093999</td>\n","      <td>0.141093</td>\n","      <td>0.006346</td>\n","      <td>1070.106615</td>\n","      <td>184355.942417</td>\n","      <td>1596.412872</td>\n","      <td>166441.494769</td>\n","      <td>2184.745799</td>\n","      <td>...</td>\n","      <td>0.780874</td>\n","      <td>44.427753</td>\n","      <td>-3.319597</td>\n","      <td>50.206673</td>\n","      <td>0.636965</td>\n","      <td>37.319130</td>\n","      <td>-0.619121</td>\n","      <td>37.259739</td>\n","      <td>-3.407448</td>\n","      <td>31.949339</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>661794</td>\n","      <td>0.308526</td>\n","      <td>0.087841</td>\n","      <td>0.091529</td>\n","      <td>0.002303</td>\n","      <td>1835.004266</td>\n","      <td>343399.939274</td>\n","      <td>1748.172116</td>\n","      <td>88445.209036</td>\n","      <td>3579.757627</td>\n","      <td>...</td>\n","      <td>-4.520576</td>\n","      <td>86.099236</td>\n","      <td>-5.454034</td>\n","      <td>75.269707</td>\n","      <td>-0.916874</td>\n","      <td>53.613918</td>\n","      <td>-4.404827</td>\n","      <td>62.910812</td>\n","      <td>-11.703234</td>\n","      <td>55.195160</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>661794</td>\n","      <td>0.352063</td>\n","      <td>0.080487</td>\n","      <td>0.079486</td>\n","      <td>0.000345</td>\n","      <td>2008.149458</td>\n","      <td>282174.689224</td>\n","      <td>2106.541053</td>\n","      <td>88609.749506</td>\n","      <td>4253.557033</td>\n","      <td>...</td>\n","      <td>1.789867</td>\n","      <td>45.050526</td>\n","      <td>-13.289984</td>\n","      <td>41.754955</td>\n","      <td>2.484145</td>\n","      <td>36.778877</td>\n","      <td>-6.713265</td>\n","      <td>54.866825</td>\n","      <td>-1.193787</td>\n","      <td>49.950665</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>661794</td>\n","      <td>0.398687</td>\n","      <td>0.075086</td>\n","      <td>0.076458</td>\n","      <td>0.000588</td>\n","      <td>2006.843354</td>\n","      <td>182114.709510</td>\n","      <td>2068.942009</td>\n","      <td>82426.016726</td>\n","      <td>4149.338328</td>\n","      <td>...</td>\n","      <td>3.739020</td>\n","      <td>33.851742</td>\n","      <td>-10.848309</td>\n","      <td>39.395096</td>\n","      <td>1.881229</td>\n","      <td>32.010040</td>\n","      <td>-7.461491</td>\n","      <td>39.196327</td>\n","      <td>-2.795338</td>\n","      <td>31.773624</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>661794</td>\n","      <td>0.432142</td>\n","      <td>0.075268</td>\n","      <td>0.081651</td>\n","      <td>0.000322</td>\n","      <td>2077.526598</td>\n","      <td>231657.968040</td>\n","      <td>1927.293153</td>\n","      <td>74717.124394</td>\n","      <td>4031.405321</td>\n","      <td>...</td>\n","      <td>1.838090</td>\n","      <td>33.597008</td>\n","      <td>-12.845291</td>\n","      <td>36.367264</td>\n","      <td>3.440978</td>\n","      <td>36.001110</td>\n","      <td>-12.588070</td>\n","      <td>42.502201</td>\n","      <td>-2.106337</td>\n","      <td>29.865515</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>661794</td>\n","      <td>0.362485</td>\n","      <td>0.091506</td>\n","      <td>0.083860</td>\n","      <td>0.001211</td>\n","      <td>1398.699344</td>\n","      <td>240318.731073</td>\n","      <td>1818.450280</td>\n","      <td>109090.207161</td>\n","      <td>3015.631004</td>\n","      <td>...</td>\n","      <td>-2.812176</td>\n","      <td>46.324894</td>\n","      <td>-4.416050</td>\n","      <td>43.583942</td>\n","      <td>1.556207</td>\n","      <td>34.331261</td>\n","      <td>-5.041897</td>\n","      <td>47.227180</td>\n","      <td>-3.590644</td>\n","      <td>41.299088</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>661794</td>\n","      <td>0.358401</td>\n","      <td>0.085884</td>\n","      <td>0.054454</td>\n","      <td>0.000336</td>\n","      <td>1609.795082</td>\n","      <td>422203.216152</td>\n","      <td>1797.213044</td>\n","      <td>120115.632927</td>\n","      <td>3246.908930</td>\n","      <td>...</td>\n","      <td>1.794104</td>\n","      <td>59.167755</td>\n","      <td>-7.069775</td>\n","      <td>73.760391</td>\n","      <td>0.028346</td>\n","      <td>76.504326</td>\n","      <td>-2.025783</td>\n","      <td>72.189316</td>\n","      <td>1.155239</td>\n","      <td>49.662510</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows Ã— 58 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5918a515-1ca0-4231-a1a3-4d7bc3474107')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5918a515-1ca0-4231-a1a3-4d7bc3474107 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5918a515-1ca0-4231-a1a3-4d7bc3474107');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(750, 10)\n","Epoch 1/8000000\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-ff18491d102e>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# now we just update our model fit call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m history = model.fit(X_train,\n\u001b[0m\u001b[1;32m     28\u001b[0m                     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/losses.py\", line 1984, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/usr/local/lib/python3.9/dist-packages/keras/backend.py\", line 5559, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (10, 10) and (10, 5) are incompatible\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"1IiC1wvp8jB8"},"execution_count":null,"outputs":[]}]}