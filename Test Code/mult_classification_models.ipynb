{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "import os\n",
    "os.chdir('C:\\\\Users\\\\blake\\\\OneDrive - The University of Texas at Austin\\\\Project')\n",
    "\n",
    "metal_df = pd.read_csv('Data\\\\metal_features.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           tempo  zcr_mean   zcr_var  rmse_mean  rmse_var  centroid_mean   \n",
      "0     151.999081  0.074351  0.001561   0.114258  0.002752    2181.215203  \\\n",
      "1      66.256010  0.111619  0.004041   0.018642  0.000021    2509.989081   \n",
      "2     161.499023  0.107580  0.002811   0.084716  0.000365    2343.956293   \n",
      "3     161.499023  0.110319  0.002615   0.076693  0.000777    2424.316543   \n",
      "4     151.999081  0.089109  0.001700   0.152179  0.003460    2391.270454   \n",
      "...          ...       ...       ...        ...       ...            ...   \n",
      "2003  172.265625  0.179256  0.003895   0.054047  0.000416    3318.041756   \n",
      "2004   95.703125  0.156924  0.000821   0.159225  0.001927    2455.779320   \n",
      "2005   89.102909  0.158438  0.000756   0.158723  0.000822    2974.813046   \n",
      "2006  123.046875  0.144889  0.001550   0.060306  0.000275    2763.773133   \n",
      "2007   99.384014  0.130489  0.000954   0.139728  0.001106    2393.238356   \n",
      "\n",
      "       centroid_var  bandwidth_mean  bandwidth_var  contrast_mean  ...   \n",
      "0     482610.507049     2558.850666  174764.598383      21.296943  ...  \\\n",
      "1     844148.519051     2572.406109  246261.986102      22.539447  ...   \n",
      "2     716615.371758     2474.222708  340194.578739      22.117780  ...   \n",
      "3     612365.527333     2492.341742  241954.945353      21.343718  ...   \n",
      "4     448760.061988     2641.490260  151274.051444      22.995294  ...   \n",
      "...             ...             ...            ...            ...  ...   \n",
      "2003  280698.311680     2752.973537   68262.169549      19.941042  ...   \n",
      "2004   69023.231425     2090.054170   93805.436561      20.621860  ...   \n",
      "2005   73121.042523     2626.600472   37562.709773      20.578968  ...   \n",
      "2006  211629.171008     2488.216681  106243.679110      20.900144  ...   \n",
      "2007  255398.044483     2223.942628  201966.304699      21.392127  ...   \n",
      "\n",
      "      mfcc16_mean  mfcc16_var  mfcc17_mean  mfcc17_var  mfcc18_mean   \n",
      "0        0.592374   32.585410    -2.084050   23.633520    -1.124526  \\\n",
      "1        6.129311   34.933400    -7.698192   41.718480    -0.720495   \n",
      "2        5.128003   26.396950    -6.747054   30.311937     0.694298   \n",
      "3        2.093907   28.635975    -5.482922   27.961150     1.806943   \n",
      "4        4.126497   40.205240    -3.384828   35.070404    -0.047709   \n",
      "...           ...         ...          ...         ...          ...   \n",
      "2003     0.415713   18.897371    -3.820183   25.815790    -0.236608   \n",
      "2004    -1.320289   23.298548    -8.588392   33.177296    -2.938309   \n",
      "2005    -0.804291   25.815720    -5.401749   16.727884    -2.288102   \n",
      "2006    -3.206482   18.866701    -7.377448   20.212032    -6.647660   \n",
      "2007     5.092002   23.933926    -2.520834   27.309591     0.576603   \n",
      "\n",
      "      mfcc18_var  mfcc19_mean  mfcc19_var  mfcc20_mean  mfcc20_var  \n",
      "0      28.282341    -0.585091   28.417725    -1.251430   22.480503  \n",
      "1      33.528008    -2.418910   30.387417    -1.870767   28.643364  \n",
      "2      35.899055    -1.424906   32.738450    -0.471814   32.966187  \n",
      "3      28.260510    -1.277048   28.995024    -0.366549   35.731552  \n",
      "4      57.063650    -2.328597   34.096700    -2.180690   46.112010  \n",
      "...          ...          ...         ...          ...         ...  \n",
      "2003   19.299862    -1.737713   20.367432     1.836022   18.513490  \n",
      "2004   31.151134    -0.684279   33.096900    -2.521253   18.757652  \n",
      "2005   19.380968    -0.139133   21.484268    -1.689018   21.136440  \n",
      "2006   16.984290    -2.452555   21.935274     1.481844   20.904577  \n",
      "2007   25.018385    -0.539950   17.986185     2.919788   30.386162  \n",
      "\n",
      "[2008 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "X = metal_df.drop(columns=['title', 'Unnamed: 0', 'subgenre'])\n",
    "y = metal_df['subgenre']\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "        ..\n",
      "2003    11\n",
      "2004    11\n",
      "2005    11\n",
      "2006    11\n",
      "2007    11\n",
      "Name: subgenre, Length: 2008, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def label_to_int(label):\n",
    "    if label == 'alternative':\n",
    "        return \"1\"\n",
    "    elif label == 'death':\n",
    "        return \"2\"\n",
    "    elif label == 'folk':\n",
    "        return \"3\"\n",
    "    elif label == 'glam':\n",
    "        return \"4\"\n",
    "    elif label == 'industrial':\n",
    "        return \"5\"\n",
    "    elif label == 'metalcore':\n",
    "        return \"6\"\n",
    "    elif label == 'nu':\n",
    "        return \"7\"\n",
    "    elif label == 'NWOBHM':\n",
    "        return \"8\"\n",
    "    elif label == 'progressive':\n",
    "        return \"9\"\n",
    "    elif label == 'symphonic':\n",
    "        return \"10\"\n",
    "    elif label == 'thrash':\n",
    "        return \"11\"\n",
    "    \n",
    "y = y.apply(lambda x: label_to_int(x))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train dimension=  (1606, 61)\n",
      "X_test dimension=  (402, 61)\n",
      "y_train dimension=  (1606,)\n",
      "y_train dimension=  (402,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size= 0.2, random_state = 1)\n",
    "\n",
    "print('X_train dimension= ', X_train.shape)\n",
    "print('X_test dimension= ', X_test.shape)\n",
    "print('y_train dimension= ', y_train.shape)\n",
    "print('y_train dimension= ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27  3  1  0  0  0  9  0  0  0  0]\n",
      " [10 26  1  0  0  0  7  0  0  0  0]\n",
      " [11  1 25  0  0  0 14  0  0  0  0]\n",
      " [ 6  1 12  0  0  0  2  0  0  0  0]\n",
      " [15  7  1  0  0  0 14  0  0  0  0]\n",
      " [30  3  0  0  0  0 13  0  0  0  0]\n",
      " [ 5  7  1  0  0  0 18  0  0  0  0]\n",
      " [ 6  4  0  0  0  0 10  0  0  0  0]\n",
      " [26  7  1  0  0  0 11  0  0  0  0]\n",
      " [26  1  3  0  0  0  1  0  0  0  0]\n",
      " [23  2  3  0  0  0  8  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "dtree_model = DecisionTreeClassifier(max_depth=2).fit(X_train, y_train)\n",
    "dtree_predictions = dtree_model.predict(X_test)\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, dtree_predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, random_state = 0)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17729083665338646\n",
      "[[ 8 10  4  2  1  5  7  1 14  1  0]\n",
      " [12 17  6  1  4  5  0  1  4  0  5]\n",
      " [ 7  1 21  2  6  8  5  0  2  1  8]\n",
      " [ 1  2 10  5  3  3  2  0  1  1  4]\n",
      " [ 3  3 17  1 10  8  2  1  3  0  1]\n",
      " [ 9  5 12  0  6  5  2  2  9  0  2]\n",
      " [ 8  7  4  1  4  3  7  1  7  0  1]\n",
      " [ 1  3  1  1  1  1  6  0  3  0  1]\n",
      " [15 11  5  0  1  7  7  1  9  1  3]\n",
      " [ 3  8  6  2  2  1  2  1  3  2  4]\n",
      " [ 5  9 11  2  2  5  4  1  1  0  5]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 10).fit(X_train, y_train)\n",
    "accuracy = knn.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "\n",
    "knn_predictions = knn.predict(X_test) \n",
    "cm = metrics.confusion_matrix(y_test, knn_predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17928286852589642\n",
      "[[ 5  1  1  4  1  2  1  2 23 13  0]\n",
      " [ 2  9  0  3  0  0  1  1  6 33  0]\n",
      " [ 0  0  0 32  2  2  1  1  6 17  0]\n",
      " [ 0  1  1 21  2  1  0  0  1  5  0]\n",
      " [ 1  0  3  9  0  1  0  1 12 20  2]\n",
      " [ 0  0  0  3  0  3  0  2 16 28  0]\n",
      " [ 0  2  1  6  1  0  1  5 20  7  0]\n",
      " [ 0  0  0  2  1  2  0  4  7  1  1]\n",
      " [ 7  0  0  8  2  0  2  4 26 11  0]\n",
      " [ 2  0  0  5  1  1  1  0  4 20  0]\n",
      " [ 0  0  0  7  0  4  0  2  6 25  1]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, random_state = 0)\n",
    "  \n",
    "# training a Naive Bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB().fit(X_train, y_train)\n",
    "gnb_predictions = gnb.predict(X_test)\n",
    "  \n",
    "# accuracy on X_test\n",
    "accuracy = gnb.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "  \n",
    "# creating a confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, gnb_predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF THE MODEL:  0.45439469320066334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size = 0.30)\n",
    "clf = RandomForestClassifier(n_estimators = 2000)  \n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\blake\\OneDrive - The University of Texas at Austin\\Project\\Test Code\\feature_extractor.py:11: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio_file = librosa.load(audio_path, offset=60.0, duration=30.0)\n",
      "c:\\Users\\blake\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    }
   ],
   "source": [
    "import feature_extractor\n",
    "input_path = 'Data\\\\girls_girls_girls.wav'\n",
    "input_features = feature_extractor.extract_features_from_wav_file(input_path)\n",
    "input_features = input_features.drop(['title'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4']\n"
     ]
    }
   ],
   "source": [
    "input_pred = clf.predict(input_features)\n",
    "print(input_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_int_all_genres(label):\n",
    "    if label == 'blues':\n",
    "        return \"1\"\n",
    "    elif label == 'classical':\n",
    "        return \"2\"\n",
    "    elif label == 'country':\n",
    "        return \"3\"\n",
    "    elif label == 'disco':\n",
    "        return \"4\"\n",
    "    elif label == 'hiphop':\n",
    "        return \"5\"\n",
    "    elif label == 'jazz':\n",
    "        return \"6\"\n",
    "    elif label == 'metal':\n",
    "        return \"7\"\n",
    "    elif label == 'pop':\n",
    "        return \"8\"\n",
    "    elif label == 'reggae':\n",
    "        return \"9\"\n",
    "    elif label == 'rock':\n",
    "        return \"10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 63)\n"
     ]
    }
   ],
   "source": [
    "all_genre_features = pd.read_csv('Data\\\\new_features.csv')\n",
    "genres = []\n",
    "for song in all_genre_features.title:\n",
    "    genre = song.split('.')\n",
    "    genres.append(genre[0])\n",
    "\n",
    "print(all_genre_features.shape)\n",
    "all_genre_features['genre'] = genres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "994    10\n",
      "995    10\n",
      "996    10\n",
      "997    10\n",
      "998    10\n",
      "Name: genre, Length: 999, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X = all_genre_features.drop(columns=['title', 'Unnamed: 0', 'genre'])\n",
    "y = all_genre_features['genre']\n",
    "\n",
    "y = y.apply(lambda x: label_to_int_all_genres(x))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF THE MODEL:  0.78\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size = 0.30)\n",
    "clf = RandomForestClassifier(n_estimators = 500)  \n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\blake\\OneDrive - The University of Texas at Austin\\Project\\Test Code\\feature_extractor.py:11: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio_file = librosa.load(audio_path, offset=60.0, duration=30.0)\n",
      "c:\\Users\\blake\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    }
   ],
   "source": [
    "import feature_extractor\n",
    "input_path = 'Data\\\\call_me_little_sunshine.wav'\n",
    "input_features = feature_extractor.extract_features_from_wav_file(input_path)\n",
    "input_features = input_features.drop(['title'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5']\n"
     ]
    }
   ],
   "source": [
    "input_pred = clf.predict(input_features)\n",
    "print(input_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26\n",
      "[[ 8  4  1  3  1  0  1  1  1  6]\n",
      " [ 3  3  1  3  1  3  2  4  2  1]\n",
      " [ 0  0 12  0  0  0  2  0  0  1]\n",
      " [ 3  3  1  2  3  0  3  1  1  7]\n",
      " [ 2  5  0  5  5  1  0  2  2  5]\n",
      " [ 2  3  0  1  4  6  0  1  8  5]\n",
      " [ 8  3  3  2  0  1  8  1  0  4]\n",
      " [ 5  1  8  1  1  2  0  5  0  0]\n",
      " [ 1  1  0  3  0  8  0  0  7  9]\n",
      " [ 2  3  0  1  0  3  0  0  5  9]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, random_state = 0)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 10).fit(X_train, y_train)\n",
    "accuracy = knn.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "\n",
    "knn_predictions = knn.predict(X_test) \n",
    "cm = metrics.confusion_matrix(y_test, knn_predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.496\n",
      "[[ 8  1  0  3  0  0  0  4  0  5]\n",
      " [ 0  4  0  5  6  0  1  4  0  0]\n",
      " [ 1  0 28  0  0  0  0  0  0  0]\n",
      " [ 3  1  0 15  4  0  0  1  1  3]\n",
      " [ 1  3  0  0 12  3  0  3  1  1]\n",
      " [ 0  1  0  0  6  6  0  8  4  4]\n",
      " [ 2  1  4  0  2  0  4  5  1  0]\n",
      " [ 0  3  0  1  4  1  0 19  0  0]\n",
      " [ 0  2  0  0  6  0  2  1 13  3]\n",
      " [ 1  1  0  2  1  3  0  0  2 15]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, random_state = 10)\n",
    "  \n",
    "# training a Naive Bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB().fit(X_train, y_train)\n",
    "gnb_predictions = gnb.predict(X_test)\n",
    "  \n",
    "# accuracy on X_test\n",
    "accuracy = gnb.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "  \n",
    "# creating a confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, gnb_predictions)\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
